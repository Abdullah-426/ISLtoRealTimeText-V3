LSTM:
------------------------------------------------------------------------------------

(isl-env) PS E:\Data Science Project\ISLtoRealTimeText-V3> python train_model_v5.py `
>>   --split_root "Dataset_Split" `
>>   --model lstm `
>>   --use_attention `
>>   --batch 24 `
>>   --epochs 80 `
>>   --lr 3e-4 `
>>   --optimizer adamw --weight_decay 1e-4 `
>>   --face_scale 0.75 --face_dropout 0.20 --hand_dropout 0.10 `
>>   --time_shift 2 --temporal_cutout 1 `
>>   --time_warp --warp_min 0.95 --warp_max 1.08 `
>>   --temporal_crop --crop_min_frac 0.92 `
>>   --xy_scale 0.008 --xy_shift 0.008 --z_noise 0.002 `
>>   --landmark_dropout 0.015 `
>>   --dropout 0.45 `
>>   --lstm_w1 224 --lstm_w2 128 `
>>   --l2 1e-4 `
>>   --add_deltas `
>>   --tta 8 --tta_time_warp --tta_temporal_crop `
>>   --shuffle_buf 2048 `
>>   --num_threads 8 `
>>   --no_tfjs --no_tflite `
>>   --save_dir "models/isl_v5_lstm_mild_aw_deltas"
>> 
2025-10-23 23:11:48.594519: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-23 23:11:50.291265: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[INFO] classes=104  seq_len=48  feat_dim_in=3324
[INFO] train=12238  val=1528  test=1535
[INFO] class_weights: {0: 0.9806089743589743, 1: 0.9888493859082095, 2: 0.9806089743589743, 3: 1.0144230769230769, 4: 0.9888493859082095, 5: 0.9806089743589743, 6: 0.9806089743589743, 7: 0.9806089743589743, 8: 0.9806089743589743, 9: 0.9806089743589743, 10: 0.9806089743589743, 11: 0.9806089743589743, 12: 0.9806089743589743, 13: 0.9806089743589743, 14: 0.9806089743589743, 15: 1.238663967611336, 16: 0.9806089743589743, 17: 0.9806089743589743, 18: 0.9806089743589743, 19: 0.9806089743589743, 20: 0.9806089743589743, 21: 0.9806089743589743, 22: 0.9806089743589743, 23: 0.9806089743589743, 24: 0.9806089743589743, 25: 0.9972294654498044, 26: 0.9806089743589743, 27: 0.9806089743589743, 28: 0.9806089743589743, 29: 0.9806089743589743, 30: 0.9806089743589743, 31: 0.9806089743589743, 32: 0.9888493859082095, 33: 0.9888493859082095, 34: 0.9806089743589743, 35: 0.9806089743589743, 36: 0.9806089743589743, 37: 0.9806089743589743, 38: 0.9806089743589743, 39: 0.9806089743589743, 40: 0.9806089743589743, 41: 1.1767307692307691, 42: 0.9888493859082095, 43: 0.9806089743589743, 44: 0.9806089743589743, 45: 0.9806089743589743, 46: 0.9806089743589743, 47: 0.9806089743589743, 48: 0.9888493859082095, 49: 1.0895655270655271, 50: 0.9806089743589743, 51: 0.9806089743589743, 52: 0.9806089743589743, 53: 1.1767307692307691, 54: 1.0506524725274726, 55: 0.9806089743589743, 56: 1.2790551839464883, 57: 0.9806089743589743, 58: 0.9806089743589743, 59: 0.9806089743589743, 60: 0.9888493859082095, 61: 0.9806089743589743, 62: 0.9806089743589743, 63: 0.9806089743589743, 64: 1.4008699633699633, 65: 0.9806089743589743, 66: 0.9806089743589743, 67: 0.9806089743589743, 68: 1.0506524725274726, 69: 0.9806089743589743, 70: 0.9888493859082095, 71: 0.9806089743589743, 72: 0.9806089743589743, 73: 1.0144230769230769, 74: 1.4008699633699633, 75: 0.9888493859082095, 76: 0.9806089743589743, 77: 0.9806089743589743, 78: 0.9806089743589743, 79: 0.9806089743589743, 80: 0.9806089743589743, 81: 0.9806089743589743, 82: 1.0144230769230769, 83: 0.9806089743589743, 84: 0.9806089743589743, 85: 0.9806089743589743, 86: 0.9806089743589743, 87: 0.9806089743589743, 88: 0.9806089743589743, 89: 1.1314718934911243, 90: 1.0144230769230769, 91: 1.0144230769230769, 92: 0.9806089743589743, 93: 0.9806089743589743, 94: 0.9972294654498044, 95: 0.9806089743589743, 96: 0.9806089743589743, 97: 0.9806089743589743, 98: 0.9806089743589743, 99: 0.9806089743589743, 100: 0.9806089743589743, 101: 0.9806089743589743, 102: 0.9806089743589743, 103: 0.9806089743589743}
2025-10-23 23:11:57.642337: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From E:\Data Science Project\ISLtoRealTimeText-V3\isl-env\Lib\site-packages\keras\src\backend\tensorflow\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

Model: "ISL_BiLSTM_Attn_v5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ seq (InputLayer)              │ (None, 48, 3324)          │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ bidirectional (Bidirectional) │ (None, 48, 448)           │       6,359,808 │ seq[0][0]                  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ layer_normalization           │ (None, 48, 448)           │             896 │ bidirectional[0][0]        │
│ (LayerNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout (Dropout)             │ (None, 48, 448)           │               0 │ layer_normalization[0][0]  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ bidirectional_1               │ (None, 48, 256)           │         590,848 │ dropout[0][0]              │
│ (Bidirectional)               │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense (Dense)                 │ (None, 48, 256)           │         114,944 │ dropout[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ layer_normalization_1         │ (None, 48, 256)           │             512 │ bidirectional_1[0][0]      │
│ (LayerNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add (Add)                     │ (None, 48, 256)           │               0 │ dense[0][0],               │
│                               │                           │                 │ layer_normalization_1[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ temporal_attention            │ (None, 256)               │          33,025 │ add[0][0]                  │
│ (TemporalAttentionLayer)      │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense_3 (Dense)               │ (None, 256)               │          65,792 │ temporal_attention[0][0]   │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization           │ (None, 256)               │           1,024 │ dense_3[0][0]              │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation (Activation)       │ (None, 256)               │               0 │ batch_normalization[0][0]  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_1 (Dropout)           │ (None, 256)               │               0 │ activation[0][0]           │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense_4 (Dense)               │ (None, 128)               │          32,896 │ dropout_1[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_1         │ (None, 128)               │             512 │ dense_4[0][0]              │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_1 (Activation)     │ (None, 128)               │               0 │ batch_normalization_1[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense_5 (Dense)               │ (None, 104)               │          13,416 │ activation_1[0][0]         │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 7,213,673 (27.52 MB)
 Trainable params: 7,212,905 (27.52 MB)
 Non-trainable params: 768 (3.00 KB)
Epoch 1/80
2025-10-23 23:12:19.247199: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 622 of 2048
2025-10-23 23:12:39.246901: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 1986 of 2048
2025-10-23 23:12:40.291312: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.
    510/Unknown 660s 1s/step - loss: 4.90832025-10-23 23:22:59.265946: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]
E:\Data Science Project\ISLtoRealTimeText-V3\isl-env\Lib\site-packages\keras\src\trainers\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
2025-10-23 23:23:06.988828: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.0484  val_top3=0.1060
510/510 ━━━━━━━━━━━━━━━━━━━━ 713s 1s/step - loss: 5.0197 - val_loss: 4.6890 - val_accuracy: 0.0484 - val_top3: 0.1060 - learning_rate: 3.0000e-04       
Epoch 2/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 795ms/step - loss: 4.22432025-10-23 23:30:41.497693: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.0602  val_top3=0.1401
510/510 ━━━━━━━━━━━━━━━━━━━━ 437s 848ms/step - loss: 4.0966 - val_loss: 4.4632 - val_accuracy: 0.0602 - val_top3: 0.1401 - learning_rate: 3.0000e-04    
Epoch 3/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 725ms/step - loss: 3.76052025-10-23 23:37:27.395704: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.1093  val_top3=0.2310
510/510 ━━━━━━━━━━━━━━━━━━━━ 419s 817ms/step - loss: 3.5513 - val_loss: 4.3135 - val_accuracy: 0.1093 - val_top3: 0.2310 - learning_rate: 3.0000e-04
Epoch 4/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 890ms/step - loss: 3.2931  
[EvalCallback] val_accuracy=0.1505  val_top3=0.3593
510/510 ━━━━━━━━━━━━━━━━━━━━ 503s 981ms/step - loss: 3.0749 - val_loss: 3.6953 - val_accuracy: 0.1505 - val_top3: 0.3593 - learning_rate: 3.0000e-04
Epoch 5/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 923ms/step - loss: 2.8902  
[EvalCallback] val_accuracy=0.2088  val_top3=0.3953
510/510 ━━━━━━━━━━━━━━━━━━━━ 524s 1s/step - loss: 2.7045 - val_loss: 3.8391 - val_accuracy: 0.2088 - val_top3: 0.3953 - learning_rate: 3.0000e-04
Epoch 6/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 912ms/step - loss: 2.59182025-10-24 00:03:03.091394: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.2441  val_top3=0.4274
510/510 ━━━━━━━━━━━━━━━━━━━━ 518s 1s/step - loss: 2.4286 - val_loss: 4.0790 - val_accuracy: 0.2441 - val_top3: 0.4274 - learning_rate: 3.0000e-04
Epoch 7/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 914ms/step - loss: 2.3129  
[EvalCallback] val_accuracy=0.3410  val_top3=0.5772
510/510 ━━━━━━━━━━━━━━━━━━━━ 519s 1s/step - loss: 2.1703 - val_loss: 2.9529 - val_accuracy: 0.3410 - val_top3: 0.5772 - learning_rate: 3.0000e-04
Epoch 8/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 925ms/step - loss: 2.0627   
[EvalCallback] val_accuracy=0.2991  val_top3=0.5681
510/510 ━━━━━━━━━━━━━━━━━━━━ 524s 1s/step - loss: 1.9343 - val_loss: 3.1826 - val_accuracy: 0.2991 - val_top3: 0.5681 - learning_rate: 3.0000e-04       
Epoch 9/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 920ms/step - loss: 1.8802  
[EvalCallback] val_accuracy=0.3613  val_top3=0.6211
510/510 ━━━━━━━━━━━━━━━━━━━━ 522s 1s/step - loss: 1.7615 - val_loss: 2.7857 - val_accuracy: 0.3613 - val_top3: 0.6211 - learning_rate: 3.0000e-04
Epoch 10/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 848ms/step - loss: 1.7283  
[EvalCallback] val_accuracy=0.4274  val_top3=0.7212
510/510 ━━━━━━━━━━━━━━━━━━━━ 466s 907ms/step - loss: 1.6271 - val_loss: 2.4312 - val_accuracy: 0.4274 - val_top3: 0.7212 - learning_rate: 3.0000e-04
Epoch 11/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 806ms/step - loss: 1.57612025-10-24 00:45:00.133440: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.4640  val_top3=0.7317
510/510 ━━━━━━━━━━━━━━━━━━━━ 477s 931ms/step - loss: 1.5029 - val_loss: 2.3856 - val_accuracy: 0.4640 - val_top3: 0.7317 - learning_rate: 3.0000e-04
Epoch 12/80
2025-10-24 00:45:51.918523: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 754 of 2048
2025-10-24 00:46:11.107269: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 976ms/step - loss: 1.4858   
[EvalCallback] val_accuracy=0.5288  val_top3=0.8024
510/510 ━━━━━━━━━━━━━━━━━━━━ 583s 1s/step - loss: 1.4167 - val_loss: 2.1403 - val_accuracy: 0.5288 - val_top3: 0.8024 - learning_rate: 3.0000e-04
Epoch 13/80
2025-10-24 00:55:34.400831: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 881 of 2048
2025-10-24 00:55:44.399848: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 1809 of 2048
2025-10-24 00:55:47.150244: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 778ms/step - loss: 1.3442   
[EvalCallback] val_accuracy=0.4791  val_top3=0.7559
510/510 ━━━━━━━━━━━━━━━━━━━━ 451s 840ms/step - loss: 1.3046 - val_loss: 2.3638 - val_accuracy: 0.4791 - val_top3: 0.7559 - learning_rate: 3.0000e-04    
Epoch 14/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 855ms/step - loss: 1.2981  
[EvalCallback] val_accuracy=0.5321  val_top3=0.8658
510/510 ━━━━━━━━━━━━━━━━━━━━ 478s 933ms/step - loss: 1.2463 - val_loss: 1.9100 - val_accuracy: 0.5321 - val_top3: 0.8658 - learning_rate: 3.0000e-04
Epoch 15/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 855ms/step - loss: 1.2300  
[EvalCallback] val_accuracy=0.4921  val_top3=0.7539
510/510 ━━━━━━━━━━━━━━━━━━━━ 479s 931ms/step - loss: 1.1883 - val_loss: 2.2140 - val_accuracy: 0.4921 - val_top3: 0.7539 - learning_rate: 3.0000e-04    
Epoch 16/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 858ms/step - loss: 1.1590  
[EvalCallback] val_accuracy=0.4509  val_top3=0.7094
510/510 ━━━━━━━━━━━━━━━━━━━━ 479s 934ms/step - loss: 1.1283 - val_loss: 2.6569 - val_accuracy: 0.4509 - val_top3: 0.7094 - learning_rate: 3.0000e-04    
Epoch 17/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 858ms/step - loss: 1.1060  
[EvalCallback] val_accuracy=0.6067  val_top3=0.8868
510/510 ━━━━━━━━━━━━━━━━━━━━ 480s 935ms/step - loss: 1.1027 - val_loss: 1.7709 - val_accuracy: 0.6067 - val_top3: 0.8868 - learning_rate: 3.0000e-04
Epoch 18/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 851ms/step - loss: 1.0860  
[EvalCallback] val_accuracy=0.5962  val_top3=0.8344
510/510 ━━━━━━━━━━━━━━━━━━━━ 477s 929ms/step - loss: 1.0558 - val_loss: 1.8909 - val_accuracy: 0.5962 - val_top3: 0.8344 - learning_rate: 3.0000e-04    
Epoch 19/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 858ms/step - loss: 1.0207  
[EvalCallback] val_accuracy=0.5419  val_top3=0.7899
510/510 ━━━━━━━━━━━━━━━━━━━━ 480s 936ms/step - loss: 1.0156 - val_loss: 2.1504 - val_accuracy: 0.5419 - val_top3: 0.7899 - learning_rate: 3.0000e-04    
Epoch 20/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 863ms/step - loss: 0.9976  
[EvalCallback] val_accuracy=0.6099  val_top3=0.7919
510/510 ━━━━━━━━━━━━━━━━━━━━ 483s 942ms/step - loss: 0.9898 - val_loss: 2.0293 - val_accuracy: 0.6099 - val_top3: 0.7919 - learning_rate: 3.0000e-04
Epoch 21/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 860ms/step - loss: 0.9691  
[EvalCallback] val_accuracy=0.6872  val_top3=0.8881
510/510 ━━━━━━━━━━━━━━━━━━━━ 481s 937ms/step - loss: 0.9688 - val_loss: 1.5950 - val_accuracy: 0.6872 - val_top3: 0.8881 - learning_rate: 3.0000e-04
Epoch 22/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 858ms/step - loss: 0.92232025-10-24 02:14:12.011408: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.6387  val_top3=0.8377
510/510 ━━━━━━━━━━━━━━━━━━━━ 479s 935ms/step - loss: 0.9386 - val_loss: 1.8230 - val_accuracy: 0.6387 - val_top3: 0.8377 - learning_rate: 3.0000e-04    
Epoch 23/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 857ms/step - loss: 0.8943  
[EvalCallback] val_accuracy=0.7539  val_top3=0.9346
510/510 ━━━━━━━━━━━━━━━━━━━━ 480s 935ms/step - loss: 0.9039 - val_loss: 1.3059 - val_accuracy: 0.7539 - val_top3: 0.9346 - learning_rate: 3.0000e-04
Epoch 24/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 856ms/step - loss: 0.9053  
[EvalCallback] val_accuracy=0.6538  val_top3=0.8802
510/510 ━━━━━━━━━━━━━━━━━━━━ 479s 934ms/step - loss: 0.8950 - val_loss: 1.7181 - val_accuracy: 0.6538 - val_top3: 0.8802 - learning_rate: 3.0000e-04    
Epoch 25/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 854ms/step - loss: 0.8841  
[EvalCallback] val_accuracy=0.6623  val_top3=0.8619
510/510 ━━━━━━━━━━━━━━━━━━━━ 478s 932ms/step - loss: 0.8760 - val_loss: 1.6093 - val_accuracy: 0.6623 - val_top3: 0.8619 - learning_rate: 3.0000e-04    
Epoch 26/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 851ms/step - loss: 0.8897  
[EvalCallback] val_accuracy=0.6957  val_top3=0.8868
510/510 ━━━━━━━━━━━━━━━━━━━━ 477s 930ms/step - loss: 0.8769 - val_loss: 1.5621 - val_accuracy: 0.6957 - val_top3: 0.8868 - learning_rate: 3.0000e-04    
Epoch 27/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 849ms/step - loss: 0.8507  
[EvalCallback] val_accuracy=0.5327  val_top3=0.7664
510/510 ━━━━━━━━━━━━━━━━━━━━ 476s 928ms/step - loss: 0.8548 - val_loss: 2.1926 - val_accuracy: 0.5327 - val_top3: 0.7664 - learning_rate: 3.0000e-04    
Epoch 28/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 850ms/step - loss: 0.8411  
[EvalCallback] val_accuracy=0.6459  val_top3=0.8796
510/510 ━━━━━━━━━━━━━━━━━━━━ 477s 930ms/step - loss: 0.8390 - val_loss: 1.6005 - val_accuracy: 0.6459 - val_top3: 0.8796 - learning_rate: 3.0000e-04    
Epoch 29/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 853ms/step - loss: 0.8306  
[EvalCallback] val_accuracy=0.6695  val_top3=0.8815
510/510 ━━━━━━━━━━━━━━━━━━━━ 478s 932ms/step - loss: 0.8345 - val_loss: 1.6115 - val_accuracy: 0.6695 - val_top3: 0.8815 - learning_rate: 3.0000e-04    
Epoch 30/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 851ms/step - loss: 0.7877  
[EvalCallback] val_accuracy=0.8495  val_top3=0.9620
510/510 ━━━━━━━━━━━━━━━━━━━━ 482s 939ms/step - loss: 0.7741 - val_loss: 1.0620 - val_accuracy: 0.8495 - val_top3: 0.9620 - learning_rate: 1.5000e-04
Epoch 31/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 788ms/step - loss: 0.7481  
[EvalCallback] val_accuracy=0.8370  val_top3=0.9548
510/510 ━━━━━━━━━━━━━━━━━━━━ 436s 847ms/step - loss: 0.7492 - val_loss: 1.0998 - val_accuracy: 0.8370 - val_top3: 0.9548 - learning_rate: 1.5000e-04    
Epoch 32/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 766ms/step - loss: 0.7495  
[EvalCallback] val_accuracy=0.7788  val_top3=0.9346
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 826ms/step - loss: 0.7460 - val_loss: 1.2521 - val_accuracy: 0.7788 - val_top3: 0.9346 - learning_rate: 1.5000e-04    
Epoch 33/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 764ms/step - loss: 0.7304  
[EvalCallback] val_accuracy=0.7114  val_top3=0.8907
510/510 ━━━━━━━━━━━━━━━━━━━━ 421s 824ms/step - loss: 0.7390 - val_loss: 1.5022 - val_accuracy: 0.7114 - val_top3: 0.8907 - learning_rate: 1.5000e-04    
Epoch 34/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 765ms/step - loss: 0.7276  
[EvalCallback] val_accuracy=0.8554  val_top3=0.9777
510/510 ━━━━━━━━━━━━━━━━━━━━ 422s 826ms/step - loss: 0.7280 - val_loss: 1.0193 - val_accuracy: 0.8554 - val_top3: 0.9777 - learning_rate: 1.5000e-04
Epoch 35/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 766ms/step - loss: 0.7178  
[EvalCallback] val_accuracy=0.7860  val_top3=0.9404
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 828ms/step - loss: 0.7167 - val_loss: 1.2245 - val_accuracy: 0.7860 - val_top3: 0.9404 - learning_rate: 1.5000e-04    
Epoch 36/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 761ms/step - loss: 0.7073  
[EvalCallback] val_accuracy=0.8043  val_top3=0.9490
510/510 ━━━━━━━━━━━━━━━━━━━━ 422s 823ms/step - loss: 0.7149 - val_loss: 1.1505 - val_accuracy: 0.8043 - val_top3: 0.9490 - learning_rate: 1.5000e-04    
Epoch 37/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 761ms/step - loss: 0.7058  
[EvalCallback] val_accuracy=0.8619  val_top3=0.9692
510/510 ━━━━━━━━━━━━━━━━━━━━ 422s 824ms/step - loss: 0.7074 - val_loss: 0.9999 - val_accuracy: 0.8619 - val_top3: 0.9692 - learning_rate: 1.5000e-04
Epoch 38/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 762ms/step - loss: 0.6931  
[EvalCallback] val_accuracy=0.8796  val_top3=0.9849
510/510 ━━━━━━━━━━━━━━━━━━━━ 422s 825ms/step - loss: 0.7011 - val_loss: 0.9462 - val_accuracy: 0.8796 - val_top3: 0.9849 - learning_rate: 1.5000e-04
Epoch 39/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 764ms/step - loss: 0.6921  
[EvalCallback] val_accuracy=0.8999  val_top3=0.9876
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 828ms/step - loss: 0.6954 - val_loss: 0.8983 - val_accuracy: 0.8999 - val_top3: 0.9876 - learning_rate: 1.5000e-04
Epoch 40/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 764ms/step - loss: 0.6739  
[EvalCallback] val_accuracy=0.7938  val_top3=0.9529
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 827ms/step - loss: 0.6821 - val_loss: 1.1819 - val_accuracy: 0.7938 - val_top3: 0.9529 - learning_rate: 1.5000e-04    
Epoch 41/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 759ms/step - loss: 0.6812  
[EvalCallback] val_accuracy=0.6571  val_top3=0.8508
510/510 ━━━━━━━━━━━━━━━━━━━━ 420s 822ms/step - loss: 0.6888 - val_loss: 1.7130 - val_accuracy: 0.6571 - val_top3: 0.8508 - learning_rate: 1.5000e-04    
Epoch 42/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 762ms/step - loss: 0.6835  
[EvalCallback] val_accuracy=0.7277  val_top3=0.8979
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 826ms/step - loss: 0.6818 - val_loss: 1.4480 - val_accuracy: 0.7277 - val_top3: 0.8979 - learning_rate: 1.5000e-04    
Epoch 43/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 766ms/step - loss: 0.66692025-10-24 04:49:56.294977: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.7317  val_top3=0.9071
510/510 ━━━━━━━━━━━━━━━━━━━━ 424s 829ms/step - loss: 0.6729 - val_loss: 1.4156 - val_accuracy: 0.7317 - val_top3: 0.9071 - learning_rate: 1.5000e-04    
Epoch 44/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 765ms/step - loss: 0.6649  
[EvalCallback] val_accuracy=0.8128  val_top3=0.9601
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 827ms/step - loss: 0.6666 - val_loss: 1.1417 - val_accuracy: 0.8128 - val_top3: 0.9601 - learning_rate: 1.5000e-04    
Epoch 45/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 762ms/step - loss: 0.6625  
[EvalCallback] val_accuracy=0.7847  val_top3=0.9372
510/510 ━━━━━━━━━━━━━━━━━━━━ 422s 826ms/step - loss: 0.6663 - val_loss: 1.2546 - val_accuracy: 0.7847 - val_top3: 0.9372 - learning_rate: 1.5000e-04    
Epoch 46/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 761ms/step - loss: 0.6501  
[EvalCallback] val_accuracy=0.8449  val_top3=0.9640
510/510 ━━━━━━━━━━━━━━━━━━━━ 421s 823ms/step - loss: 0.6482 - val_loss: 1.0306 - val_accuracy: 0.8449 - val_top3: 0.9640 - learning_rate: 7.5000e-05    
Epoch 47/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 764ms/step - loss: 0.6449  
[EvalCallback] val_accuracy=0.7919  val_top3=0.9398
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 827ms/step - loss: 0.6413 - val_loss: 1.2410 - val_accuracy: 0.7919 - val_top3: 0.9398 - learning_rate: 7.5000e-05    
Epoch 48/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 764ms/step - loss: 0.6379  
[EvalCallback] val_accuracy=0.7853  val_top3=0.9444
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 827ms/step - loss: 0.6403 - val_loss: 1.2257 - val_accuracy: 0.7853 - val_top3: 0.9444 - learning_rate: 7.5000e-05    
Epoch 49/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 762ms/step - loss: 0.6358  
[EvalCallback] val_accuracy=0.7467  val_top3=0.9110
510/510 ━━━━━━━━━━━━━━━━━━━━ 422s 824ms/step - loss: 0.6371 - val_loss: 1.3602 - val_accuracy: 0.7467 - val_top3: 0.9110 - learning_rate: 7.5000e-05    
Epoch 50/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 766ms/step - loss: 0.6262  
[EvalCallback] val_accuracy=0.8992  val_top3=0.9869
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 827ms/step - loss: 0.6321 - val_loss: 0.8534 - val_accuracy: 0.8992 - val_top3: 0.9869 - learning_rate: 7.5000e-05    
Epoch 51/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 766ms/step - loss: 0.6285  
[EvalCallback] val_accuracy=0.8082  val_top3=0.9732
510/510 ━━━━━━━━━━━━━━━━━━━━ 424s 829ms/step - loss: 0.6308 - val_loss: 1.1303 - val_accuracy: 0.8082 - val_top3: 0.9732 - learning_rate: 7.5000e-05    
Epoch 52/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 765ms/step - loss: 0.6222  
[EvalCallback] val_accuracy=0.7565  val_top3=0.9221
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 827ms/step - loss: 0.6255 - val_loss: 1.3588 - val_accuracy: 0.7565 - val_top3: 0.9221 - learning_rate: 7.5000e-05    
Epoch 53/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 765ms/step - loss: 0.6255  
[EvalCallback] val_accuracy=0.7670  val_top3=0.9228
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 826ms/step - loss: 0.6240 - val_loss: 1.3272 - val_accuracy: 0.7670 - val_top3: 0.9228 - learning_rate: 7.5000e-05    
Epoch 54/80
510/510 ━━━━━━━━━━━━━━━━━━━━ 0s 765ms/step - loss: 0.6207  
[EvalCallback] val_accuracy=0.8115  val_top3=0.9548
510/510 ━━━━━━━━━━━━━━━━━━━━ 423s 826ms/step - loss: 0.6240 - val_loss: 1.1482 - val_accuracy: 0.8115 - val_top3: 0.9548 - learning_rate: 7.5000e-05    
[INFO] Loaded best weights from disk.

[TEST] acc=0.9752  top3=1.0000
[OK] Artifacts saved to: models/isl_v5_lstm_mild_aw_deltas
(isl-env) PS E:\Data Science Project\ISLtoRealTimeText-V3> 




TCN:
------------------------------------------------------------------------------------
(isl-env) PS E:\Data Science Project\ISLtoRealTimeText-V3> python train_model_v5.py `
>>   --split_root "Dataset_Split" `
>>   --model tcn `
>>   --batch 32 `
>>   --epochs 60 `
>>   --lr 3e-4 --optimizer adamw --weight_decay 1e-4 `
>>   --dropout 0.45 `
>>   --time_shift 1 --temporal_cutout 0 `
>>   --xy_scale 0.006 --xy_shift 0.006 --z_noise 0.002 `
>>   --landmark_dropout 0.010 `
>>   --add_deltas `
>>   --tta 4 --tta_time_warp --tta_temporal_crop `
>>   --warp_min 0.95 --warp_max 1.08 `
>>   --temporal_crop --crop_min_frac 0.92 `
>>   --shuffle_buf 1024 `
>>   --num_threads 8 `
>>   --cache_dir ".cache/isl_v5" `
>>   --no_tfjs --no_tflite `
>>   --save_dir "models/isl_v5_tcn_deltas"
>> 
2025-10-24 11:59:42.087098: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-24 11:59:43.484112: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[INFO] classes=104  seq_len=48  feat_dim_in=3324
[INFO] train=12238  val=1528  test=1535
[INFO] class_weights: {0: 0.9806089743589743, 1: 0.9888493859082095, 2: 0.9806089743589743, 3: 1.0144230769230769, 4: 0.9888493859082095, 5: 0.9806089743589743, 6: 0.9806089743589743, 7: 0.9806089743589743, 8: 0.9806089743589743, 9: 0.9806089743589743, 10: 0.9806089743589743, 11: 0.9806089743589743, 12: 0.9806089743589743, 13: 0.9806089743589743, 14: 0.9806089743589743, 15: 1.238663967611336, 16: 0.9806089743589743, 17: 0.9806089743589743, 18: 0.9806089743589743, 19: 0.9806089743589743, 20: 0.9806089743589743, 21: 0.9806089743589743, 22: 0.9806089743589743, 23: 0.9806089743589743, 24: 0.9806089743589743, 25: 0.9972294654498044, 26: 0.9806089743589743, 27: 0.9806089743589743, 28: 0.9806089743589743, 29: 0.9806089743589743, 30: 0.9806089743589743, 31: 0.9806089743589743, 32: 0.9888493859082095, 33: 0.9888493859082095, 34: 0.9806089743589743, 35: 0.9806089743589743, 36: 0.9806089743589743, 37: 0.9806089743589743, 38: 0.9806089743589743, 39: 0.9806089743589743, 40: 0.9806089743589743, 41: 1.1767307692307691, 42: 0.9888493859082095, 43: 0.9806089743589743, 44: 0.9806089743589743, 45: 0.9806089743589743, 46: 0.9806089743589743, 47: 0.9806089743589743, 48: 0.9888493859082095, 49: 1.0895655270655271, 50: 0.9806089743589743, 51: 0.9806089743589743, 52: 0.9806089743589743, 53: 1.1767307692307691, 54: 1.0506524725274726, 55: 0.9806089743589743, 56: 1.2790551839464883, 57: 0.9806089743589743, 58: 0.9806089743589743, 59: 0.9806089743589743, 60: 0.9888493859082095, 61: 0.9806089743589743, 62: 0.9806089743589743, 63: 0.9806089743589743, 64: 1.4008699633699633, 65: 0.9806089743589743, 66: 0.9806089743589743, 67: 0.9806089743589743, 68: 1.0506524725274726, 69: 0.9806089743589743, 70: 0.9888493859082095, 71: 0.9806089743589743, 72: 0.9806089743589743, 73: 1.0144230769230769, 74: 1.4008699633699633, 75: 0.9888493859082095, 76: 0.9806089743589743, 77: 0.9806089743589743, 78: 0.9806089743589743, 79: 0.9806089743589743, 80: 0.9806089743589743, 81: 0.9806089743589743, 82: 1.0144230769230769, 83: 0.9806089743589743, 84: 0.9806089743589743, 85: 0.9806089743589743, 86: 0.9806089743589743, 87: 0.9806089743589743, 88: 0.9806089743589743, 89: 1.1314718934911243, 90: 1.0144230769230769, 91: 1.0144230769230769, 92: 0.9806089743589743, 93: 0.9806089743589743, 94: 0.9972294654498044, 95: 0.9806089743589743, 96: 0.9806089743589743, 97: 0.9806089743589743, 98: 0.9806089743589743, 99: 0.9806089743589743, 100: 0.9806089743589743, 101: 0.9806089743589743, 102: 0.9806089743589743, 103: 0.9806089743589743}
2025-10-24 11:59:49.115873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From E:\Data Science Project\ISLtoRealTimeText-V3\isl-env\Lib\site-packages\keras\src\backend\tensorflow\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

Model: "ISL_TCN_v5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                  ┃ Output Shape              ┃         Param # ┃ Connected to               ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ seq (InputLayer)              │ (None, 48, 3324)          │               0 │ -                          │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense (Dense)                 │ (None, 48, 256)           │         851,200 │ seq[0][0]                  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout (Dropout)             │ (None, 48, 256)           │               0 │ dense[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d (Conv1D)               │ (None, 48, 256)           │         327,936 │ dropout[0][0]              │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization           │ (None, 48, 256)           │           1,024 │ conv1d[0][0]               │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation (Activation)       │ (None, 48, 256)           │               0 │ batch_normalization[0][0]  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_1 (Dropout)           │ (None, 48, 256)           │               0 │ activation[0][0]           │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add (Add)                     │ (None, 48, 256)           │               0 │ dropout[0][0],             │
│                               │                           │                 │ dropout_1[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_1 (Conv1D)             │ (None, 48, 256)           │         327,936 │ add[0][0]                  │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_1         │ (None, 48, 256)           │           1,024 │ conv1d_1[0][0]             │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_1 (Activation)     │ (None, 48, 256)           │               0 │ batch_normalization_1[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_2 (Dropout)           │ (None, 48, 256)           │               0 │ activation_1[0][0]         │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add_1 (Add)                   │ (None, 48, 256)           │               0 │ add[0][0], dropout_2[0][0] │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_2 (Conv1D)             │ (None, 48, 256)           │         327,936 │ add_1[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_2         │ (None, 48, 256)           │           1,024 │ conv1d_2[0][0]             │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_2 (Activation)     │ (None, 48, 256)           │               0 │ batch_normalization_2[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_3 (Dropout)           │ (None, 48, 256)           │               0 │ activation_2[0][0]         │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add_2 (Add)                   │ (None, 48, 256)           │               0 │ add_1[0][0],               │
│                               │                           │                 │ dropout_3[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_3 (Conv1D)             │ (None, 48, 256)           │         196,864 │ add_2[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_3         │ (None, 48, 256)           │           1,024 │ conv1d_3[0][0]             │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_3 (Activation)     │ (None, 48, 256)           │               0 │ batch_normalization_3[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_4 (Dropout)           │ (None, 48, 256)           │               0 │ activation_3[0][0]         │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add_3 (Add)                   │ (None, 48, 256)           │               0 │ add_2[0][0],               │
│                               │                           │                 │ dropout_4[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ conv1d_4 (Conv1D)             │ (None, 48, 256)           │         196,864 │ add_3[0][0]                │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_4         │ (None, 48, 256)           │           1,024 │ conv1d_4[0][0]             │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_4 (Activation)     │ (None, 48, 256)           │               0 │ batch_normalization_4[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_5 (Dropout)           │ (None, 48, 256)           │               0 │ activation_4[0][0]         │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ add_4 (Add)                   │ (None, 48, 256)           │               0 │ add_3[0][0],               │
│                               │                           │                 │ dropout_5[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ temporal_attention            │ (None, 256)               │          33,025 │ add_4[0][0]                │
│ (TemporalAttentionLayer)      │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense_3 (Dense)               │ (None, 256)               │          65,792 │ temporal_attention[0][0]   │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_5         │ (None, 256)               │           1,024 │ dense_3[0][0]              │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_5 (Activation)     │ (None, 256)               │               0 │ batch_normalization_5[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dropout_6 (Dropout)           │ (None, 256)               │               0 │ activation_5[0][0]         │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense_4 (Dense)               │ (None, 128)               │          32,896 │ dropout_6[0][0]            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ batch_normalization_6         │ (None, 128)               │             512 │ dense_4[0][0]              │
│ (BatchNormalization)          │                           │                 │                            │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ activation_6 (Activation)     │ (None, 128)               │               0 │ batch_normalization_6[0][… │
├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤
│ dense_5 (Dense)               │ (None, 104)               │          13,416 │ activation_6[0][0]         │
└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘
 Total params: 2,380,521 (9.08 MB)
 Trainable params: 2,377,193 (9.07 MB)
 Non-trainable params: 3,328 (13.00 KB)
Epoch 1/60
    383/Unknown 130s 329ms/step - loss: 4.77192025-10-24 12:02:00.509865: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]
E:\Data Science Project\ISLtoRealTimeText-V3\isl-env\Lib\site-packages\keras\src\trainers\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
2025-10-24 12:02:02.085409: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.0897  val_top3=0.2042
383/383 ━━━━━━━━━━━━━━━━━━━━ 135s 342ms/step - loss: 4.6365 - val_loss: 4.1695 - val_accuracy: 0.0897 - val_top3: 0.2042 - learning_rate: 3.0000e-04
Epoch 2/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 485ms/step - loss: 3.76232025-10-24 12:05:11.190251: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.2330  val_top3=0.4025
383/383 ━━━━━━━━━━━━━━━━━━━━ 190s 496ms/step - loss: 3.4683 - val_loss: 3.4066 - val_accuracy: 0.2330 - val_top3: 0.4025 - learning_rate: 3.0000e-04    
Epoch 3/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 439ms/step - loss: 2.93682025-10-24 12:08:04.743324: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]
Epoch 3/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 439ms/step - loss: 2.93682025-10-24 12:08:04.743324: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 439ms/step - loss: 2.93682025-10-24 12:08:04.743324: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

         [[{{node IteratorGetNext}}]]


[EvalCallback] val_accuracy=0.3881  val_top3=0.6329
383/383 ━━━━━━━━━━━━━━━━━━━━ 173s 450ms/step - loss: 2.6661 - val_loss: 2.7297 - val_accuracy: 0.3881 - val_top3: 0.6329 - learning_rate: 3.0000e-04    
Epoch 4/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 464ms/step - loss: 2.3423
[EvalCallback] val_accuracy=0.3370  val_top3=0.6224
383/383 ━━━━━━━━━━━━━━━━━━━━ 183s 477ms/step - loss: 2.1288 - val_loss: 2.7948 - val_accuracy: 0.3370 - val_top3: 0.6224 - learning_rate: 3.0000e-04    
Epoch 5/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 468ms/step - loss: 1.8457
[EvalCallback] val_accuracy=0.4810  val_top3=0.7225
383/383 ━━━━━━━━━━━━━━━━━━━━ 185s 482ms/step - loss: 1.7144 - val_loss: 2.3929 - val_accuracy: 0.4810 - val_top3: 0.7225 - learning_rate: 3.0000e-04    
Epoch 6/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 457ms/step - loss: 1.48582025-10-24 12:17:10.671840: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.6473  val_top3=0.8593
383/383 ━━━━━━━━━━━━━━━━━━━━ 180s 469ms/step - loss: 1.4168 - val_loss: 1.7594 - val_accuracy: 0.6473 - val_top3: 0.8593 - learning_rate: 3.0000e-04    
Epoch 7/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 445ms/step - loss: 1.2808
[EvalCallback] val_accuracy=0.6512  val_top3=0.8619
383/383 ━━━━━━━━━━━━━━━━━━━━ 176s 459ms/step - loss: 1.2325 - val_loss: 1.7165 - val_accuracy: 0.6512 - val_top3: 0.8619 - learning_rate: 3.0000e-04    
Epoch 8/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 470ms/step - loss: 1.1401  
[EvalCallback] val_accuracy=0.8148  val_top3=0.9764
383/383 ━━━━━━━━━━━━━━━━━━━━ 185s 484ms/step - loss: 1.1269 - val_loss: 1.1263 - val_accuracy: 0.8148 - val_top3: 0.9764 - learning_rate: 3.0000e-04
Epoch 9/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 487ms/step - loss: 1.0515  
[EvalCallback] val_accuracy=0.6381  val_top3=0.8272
383/383 ━━━━━━━━━━━━━━━━━━━━ 191s 498ms/step - loss: 1.0482 - val_loss: 1.8001 - val_accuracy: 0.6381 - val_top3: 0.8272 - learning_rate: 3.0000e-04    
Epoch 10/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 465ms/step - loss: 0.9847  
[EvalCallback] val_accuracy=0.7598  val_top3=0.9143
383/383 ━━━━━━━━━━━━━━━━━━━━ 183s 477ms/step - loss: 0.9849 - val_loss: 1.3843 - val_accuracy: 0.7598 - val_top3: 0.9143 - learning_rate: 3.0000e-04    
Epoch 11/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 462ms/step - loss: 0.94732025-10-24 12:32:28.305226: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.8135  val_top3=0.9666
383/383 ━━━━━━━━━━━━━━━━━━━━ 181s 473ms/step - loss: 0.9428 - val_loss: 1.1995 - val_accuracy: 0.8135 - val_top3: 0.9666 - learning_rate: 3.0000e-04    
Epoch 12/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 459ms/step - loss: 0.9020  
[EvalCallback] val_accuracy=0.6224  val_top3=0.8429
383/383 ━━━━━━━━━━━━━━━━━━━━ 181s 472ms/step - loss: 0.9060 - val_loss: 1.8162 - val_accuracy: 0.6224 - val_top3: 0.8429 - learning_rate: 3.0000e-04    
Epoch 13/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 494ms/step - loss: 0.8673  
[EvalCallback] val_accuracy=0.5975  val_top3=0.8207
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 507ms/step - loss: 0.8621 - val_loss: 1.9783 - val_accuracy: 0.5975 - val_top3: 0.8207 - learning_rate: 3.0000e-04    
Epoch 14/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 489ms/step - loss: 0.8449  
[EvalCallback] val_accuracy=0.7245  val_top3=0.8776
383/383 ━━━━━━━━━━━━━━━━━━━━ 192s 500ms/step - loss: 0.8492 - val_loss: 1.5360 - val_accuracy: 0.7245 - val_top3: 0.8776 - learning_rate: 3.0000e-04    
Epoch 15/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 461ms/step - loss: 0.8020  
[EvalCallback] val_accuracy=0.8868  val_top3=0.9836
383/383 ━━━━━━━━━━━━━━━━━━━━ 181s 473ms/step - loss: 0.7821 - val_loss: 0.9688 - val_accuracy: 0.8868 - val_top3: 0.9836 - learning_rate: 1.5000e-04
Epoch 16/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 462ms/step - loss: 0.7544  
[EvalCallback] val_accuracy=0.8482  val_top3=0.9431
383/383 ━━━━━━━━━━━━━━━━━━━━ 182s 475ms/step - loss: 0.7521 - val_loss: 1.1478 - val_accuracy: 0.8482 - val_top3: 0.9431 - learning_rate: 1.5000e-04    
Epoch 17/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 493ms/step - loss: 0.7360  
[EvalCallback] val_accuracy=0.9306  val_top3=0.9817
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 506ms/step - loss: 0.7370 - val_loss: 0.8738 - val_accuracy: 0.9306 - val_top3: 0.9817 - learning_rate: 1.5000e-04
Epoch 18/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 488ms/step - loss: 0.7232  
[EvalCallback] val_accuracy=0.8907  val_top3=0.9647
383/383 ━━━━━━━━━━━━━━━━━━━━ 192s 500ms/step - loss: 0.7238 - val_loss: 0.9684 - val_accuracy: 0.8907 - val_top3: 0.9647 - learning_rate: 1.5000e-04    
Epoch 19/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 485ms/step - loss: 0.7065  
[EvalCallback] val_accuracy=0.8907  val_top3=0.9673
383/383 ━━━━━━━━━━━━━━━━━━━━ 191s 497ms/step - loss: 0.7084 - val_loss: 0.9833 - val_accuracy: 0.8907 - val_top3: 0.9673 - learning_rate: 1.5000e-04    
Epoch 20/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 485ms/step - loss: 0.6987  
[EvalCallback] val_accuracy=0.8364  val_top3=0.9418
383/383 ━━━━━━━━━━━━━━━━━━━━ 191s 497ms/step - loss: 0.6966 - val_loss: 1.1019 - val_accuracy: 0.8364 - val_top3: 0.9418 - learning_rate: 1.5000e-04    
Epoch 21/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 456ms/step - loss: 0.6951  
[EvalCallback] val_accuracy=0.8809  val_top3=0.9588
383/383 ━━━━━━━━━━━━━━━━━━━━ 179s 467ms/step - loss: 0.6932 - val_loss: 1.0165 - val_accuracy: 0.8809 - val_top3: 0.9588 - learning_rate: 1.5000e-04    
Epoch 22/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 469ms/step - loss: 0.68382025-10-24 13:06:47.299536: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.8226  val_top3=0.9346
383/383 ━━━━━━━━━━━━━━━━━━━━ 184s 481ms/step - loss: 0.6849 - val_loss: 1.1442 - val_accuracy: 0.8226 - val_top3: 0.9346 - learning_rate: 1.5000e-04    
Epoch 23/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 486ms/step - loss: 0.6771  
[EvalCallback] val_accuracy=0.9110  val_top3=0.9699
383/383 ━━━━━━━━━━━━━━━━━━━━ 191s 499ms/step - loss: 0.6725 - val_loss: 0.9213 - val_accuracy: 0.9110 - val_top3: 0.9699 - learning_rate: 1.5000e-04    
Epoch 24/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 487ms/step - loss: 0.6577  
[EvalCallback] val_accuracy=0.9287  val_top3=0.9614
383/383 ━━━━━━━━━━━━━━━━━━━━ 192s 499ms/step - loss: 0.6523 - val_loss: 0.8608 - val_accuracy: 0.9287 - val_top3: 0.9614 - learning_rate: 7.5000e-05    
Epoch 25/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 493ms/step - loss: 0.6461  
[EvalCallback] val_accuracy=0.9365  val_top3=0.9771
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 505ms/step - loss: 0.6426 - val_loss: 0.8281 - val_accuracy: 0.9365 - val_top3: 0.9771 - learning_rate: 7.5000e-05
Epoch 26/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 493ms/step - loss: 0.6367  
[EvalCallback] val_accuracy=0.9116  val_top3=0.9620
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 505ms/step - loss: 0.6344 - val_loss: 0.9053 - val_accuracy: 0.9116 - val_top3: 0.9620 - learning_rate: 7.5000e-05    
Epoch 27/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 491ms/step - loss: 0.6284  
[EvalCallback] val_accuracy=0.9234  val_top3=0.9692
383/383 ━━━━━━━━━━━━━━━━━━━━ 193s 504ms/step - loss: 0.6292 - val_loss: 0.8293 - val_accuracy: 0.9234 - val_top3: 0.9692 - learning_rate: 7.5000e-05    
Epoch 28/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 491ms/step - loss: 0.6245  
[EvalCallback] val_accuracy=0.9130  val_top3=0.9575
383/383 ━━━━━━━━━━━━━━━━━━━━ 193s 504ms/step - loss: 0.6250 - val_loss: 0.9203 - val_accuracy: 0.9130 - val_top3: 0.9575 - learning_rate: 7.5000e-05    
Epoch 29/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 493ms/step - loss: 0.6162  
[EvalCallback] val_accuracy=0.9306  val_top3=0.9758
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 505ms/step - loss: 0.6173 - val_loss: 0.7921 - val_accuracy: 0.9306 - val_top3: 0.9758 - learning_rate: 7.5000e-05    
Epoch 30/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 495ms/step - loss: 0.6164  
[EvalCallback] val_accuracy=0.9149  val_top3=0.9607
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 507ms/step - loss: 0.6152 - val_loss: 0.8721 - val_accuracy: 0.9149 - val_top3: 0.9607 - learning_rate: 7.5000e-05    
Epoch 31/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 494ms/step - loss: 0.6078  
[EvalCallback] val_accuracy=0.9097  val_top3=0.9712
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 506ms/step - loss: 0.6079 - val_loss: 0.8766 - val_accuracy: 0.9097 - val_top3: 0.9712 - learning_rate: 7.5000e-05    
Epoch 32/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 495ms/step - loss: 0.6063  
[EvalCallback] val_accuracy=0.9202  val_top3=0.9634
383/383 ━━━━━━━━━━━━━━━━━━━━ 195s 509ms/step - loss: 0.6077 - val_loss: 0.8483 - val_accuracy: 0.9202 - val_top3: 0.9634 - learning_rate: 7.5000e-05    
Epoch 33/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 493ms/step - loss: 0.6027  
[EvalCallback] val_accuracy=0.9424  val_top3=0.9784
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 506ms/step - loss: 0.6006 - val_loss: 0.7612 - val_accuracy: 0.9424 - val_top3: 0.9784 - learning_rate: 7.5000e-05
Epoch 34/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 495ms/step - loss: 0.5948  
[EvalCallback] val_accuracy=0.9398  val_top3=0.9699
383/383 ━━━━━━━━━━━━━━━━━━━━ 195s 508ms/step - loss: 0.5963 - val_loss: 0.7710 - val_accuracy: 0.9398 - val_top3: 0.9699 - learning_rate: 7.5000e-05    
Epoch 35/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 493ms/step - loss: 0.5937  
[EvalCallback] val_accuracy=0.9457  val_top3=0.9686
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 505ms/step - loss: 0.5940 - val_loss: 0.7618 - val_accuracy: 0.9457 - val_top3: 0.9686 - learning_rate: 7.5000e-05
Epoch 36/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 494ms/step - loss: 0.5875  
[EvalCallback] val_accuracy=0.9228  val_top3=0.9653
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 506ms/step - loss: 0.5885 - val_loss: 0.8398 - val_accuracy: 0.9228 - val_top3: 0.9653 - learning_rate: 7.5000e-05    
Epoch 37/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 497ms/step - loss: 0.5857  
[EvalCallback] val_accuracy=0.9457  val_top3=0.9784
383/383 ━━━━━━━━━━━━━━━━━━━━ 195s 510ms/step - loss: 0.5852 - val_loss: 0.7481 - val_accuracy: 0.9457 - val_top3: 0.9784 - learning_rate: 7.5000e-05    
Epoch 38/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 495ms/step - loss: 0.5848  
[EvalCallback] val_accuracy=0.9319  val_top3=0.9673
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 507ms/step - loss: 0.5840 - val_loss: 0.7931 - val_accuracy: 0.9319 - val_top3: 0.9673 - learning_rate: 7.5000e-05    
Epoch 39/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 493ms/step - loss: 0.5772  
[EvalCallback] val_accuracy=0.9247  val_top3=0.9712
383/383 ━━━━━━━━━━━━━━━━━━━━ 194s 505ms/step - loss: 0.5777 - val_loss: 0.8168 - val_accuracy: 0.9247 - val_top3: 0.9712 - learning_rate: 7.5000e-05    
Epoch 40/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 493ms/step - loss: 0.5751  
[EvalCallback] val_accuracy=0.9332  val_top3=0.9725
383/383 ━━━━━━━━━━━━━━━━━━━━ 193s 504ms/step - loss: 0.5751 - val_loss: 0.7894 - val_accuracy: 0.9332 - val_top3: 0.9725 - learning_rate: 7.5000e-05    
Epoch 41/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 452ms/step - loss: 0.5723  
[EvalCallback] val_accuracy=0.9332  val_top3=0.9673
383/383 ━━━━━━━━━━━━━━━━━━━━ 178s 464ms/step - loss: 0.5723 - val_loss: 0.7562 - val_accuracy: 0.9332 - val_top3: 0.9673 - learning_rate: 7.5000e-05    
Epoch 42/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 503ms/step - loss: 0.5713  
[EvalCallback] val_accuracy=0.8835  val_top3=0.9581
383/383 ━━━━━━━━━━━━━━━━━━━━ 197s 515ms/step - loss: 0.5707 - val_loss: 0.9222 - val_accuracy: 0.8835 - val_top3: 0.9581 - learning_rate: 7.5000e-05    
Epoch 43/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 501ms/step - loss: 0.56832025-10-24 14:14:26.094674: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
         [[{{node IteratorGetNext}}]]

[EvalCallback] val_accuracy=0.9575  val_top3=0.9764
383/383 ━━━━━━━━━━━━━━━━━━━━ 197s 515ms/step - loss: 0.5679 - val_loss: 0.6907 - val_accuracy: 0.9575 - val_top3: 0.9764 - learning_rate: 7.5000e-05
Epoch 44/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 482ms/step - loss: 0.5618  
[EvalCallback] val_accuracy=0.9496  val_top3=0.9771
383/383 ━━━━━━━━━━━━━━━━━━━━ 190s 495ms/step - loss: 0.5631 - val_loss: 0.7108 - val_accuracy: 0.9496 - val_top3: 0.9771 - learning_rate: 7.5000e-05    
Epoch 45/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 304ms/step - loss: 0.5591  
[EvalCallback] val_accuracy=0.9463  val_top3=0.9764
383/383 ━━━━━━━━━━━━━━━━━━━━ 120s 313ms/step - loss: 0.5613 - val_loss: 0.7093 - val_accuracy: 0.9463 - val_top3: 0.9764 - learning_rate: 7.5000e-05    
Epoch 46/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 298ms/step - loss: 0.5560  
[EvalCallback] val_accuracy=0.9064  val_top3=0.9719
383/383 ━━━━━━━━━━━━━━━━━━━━ 118s 307ms/step - loss: 0.5572 - val_loss: 0.8120 - val_accuracy: 0.9064 - val_top3: 0.9719 - learning_rate: 7.5000e-05    
Epoch 47/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 299ms/step - loss: 0.5560  
[EvalCallback] val_accuracy=0.9306  val_top3=0.9764
383/383 ━━━━━━━━━━━━━━━━━━━━ 118s 307ms/step - loss: 0.5573 - val_loss: 0.7782 - val_accuracy: 0.9306 - val_top3: 0.9764 - learning_rate: 7.5000e-05    
Epoch 48/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 375ms/step - loss: 0.5541  
[EvalCallback] val_accuracy=0.9267  val_top3=0.9673
383/383 ━━━━━━━━━━━━━━━━━━━━ 148s 385ms/step - loss: 0.5556 - val_loss: 0.8116 - val_accuracy: 0.9267 - val_top3: 0.9673 - learning_rate: 7.5000e-05    
Epoch 49/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 394ms/step - loss: 0.5547  
[EvalCallback] val_accuracy=0.9300  val_top3=0.9647
383/383 ━━━━━━━━━━━━━━━━━━━━ 155s 404ms/step - loss: 0.5517 - val_loss: 0.7647 - val_accuracy: 0.9300 - val_top3: 0.9647 - learning_rate: 7.5000e-05    
Epoch 50/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 391ms/step - loss: 0.5434  
[EvalCallback] val_accuracy=0.9162  val_top3=0.9699
383/383 ━━━━━━━━━━━━━━━━━━━━ 154s 401ms/step - loss: 0.5430 - val_loss: 0.8138 - val_accuracy: 0.9162 - val_top3: 0.9699 - learning_rate: 3.7500e-05    
Epoch 51/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 392ms/step - loss: 0.5411  
[EvalCallback] val_accuracy=0.9555  val_top3=0.9797
383/383 ━━━━━━━━━━━━━━━━━━━━ 154s 401ms/step - loss: 0.5415 - val_loss: 0.6884 - val_accuracy: 0.9555 - val_top3: 0.9797 - learning_rate: 3.7500e-05    
Epoch 52/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 392ms/step - loss: 0.5387  
[EvalCallback] val_accuracy=0.9182  val_top3=0.9699
383/383 ━━━━━━━━━━━━━━━━━━━━ 154s 401ms/step - loss: 0.5403 - val_loss: 0.8084 - val_accuracy: 0.9182 - val_top3: 0.9699 - learning_rate: 3.7500e-05    
Epoch 53/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 398ms/step - loss: 0.5385  
[EvalCallback] val_accuracy=0.9215  val_top3=0.9725
383/383 ━━━━━━━━━━━━━━━━━━━━ 156s 408ms/step - loss: 0.5388 - val_loss: 0.7892 - val_accuracy: 0.9215 - val_top3: 0.9725 - learning_rate: 3.7500e-05    
Epoch 54/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 397ms/step - loss: 0.5356  
[EvalCallback] val_accuracy=0.9444  val_top3=0.9771
383/383 ━━━━━━━━━━━━━━━━━━━━ 156s 407ms/step - loss: 0.5364 - val_loss: 0.7121 - val_accuracy: 0.9444 - val_top3: 0.9771 - learning_rate: 3.7500e-05    
Epoch 55/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 396ms/step - loss: 0.5347  
[EvalCallback] val_accuracy=0.9385  val_top3=0.9738
383/383 ━━━━━━━━━━━━━━━━━━━━ 156s 406ms/step - loss: 0.5353 - val_loss: 0.7251 - val_accuracy: 0.9385 - val_top3: 0.9738 - learning_rate: 3.7500e-05    
Epoch 56/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 395ms/step - loss: 0.5340  
[EvalCallback] val_accuracy=0.9241  val_top3=0.9699
383/383 ━━━━━━━━━━━━━━━━━━━━ 155s 405ms/step - loss: 0.5342 - val_loss: 0.7980 - val_accuracy: 0.9241 - val_top3: 0.9699 - learning_rate: 3.7500e-05    
Epoch 57/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 394ms/step - loss: 0.5310  
[EvalCallback] val_accuracy=0.9529  val_top3=0.9745
383/383 ━━━━━━━━━━━━━━━━━━━━ 155s 404ms/step - loss: 0.5310 - val_loss: 0.7049 - val_accuracy: 0.9529 - val_top3: 0.9745 - learning_rate: 3.7500e-05    
Epoch 58/60
383/383 ━━━━━━━━━━━━━━━━━━━━ 0s 392ms/step - loss: 0.5294  
[EvalCallback] val_accuracy=0.9437  val_top3=0.9679
383/383 ━━━━━━━━━━━━━━━━━━━━ 154s 402ms/step - loss: 0.5304 - val_loss: 0.7344 - val_accuracy: 0.9437 - val_top3: 0.9679 - learning_rate: 1.8750e-05    
[INFO] Loaded best weights from disk.

[TEST] acc=0.9818  top3=1.0000
[OK] Artifacts saved to: models/isl_v5_tcn_deltas
(isl-env) PS E:\Data Science Project\ISLtoRealTimeText-V3> 